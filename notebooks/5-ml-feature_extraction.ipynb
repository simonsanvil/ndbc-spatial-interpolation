{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, warnings\n",
    "from functools import partial\n",
    "\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "from shapely import geometry\n",
    "\n",
    "# utils\n",
    "from joblib import Parallel, delayed\n",
    "from pandas import IndexSlice as idx\n",
    "from IPython.display import display\n",
    "\n",
    "# viz\n",
    "import folium\n",
    "\n",
    "# local imports\n",
    "from spatial_interpolation import data, utils\n",
    "from spatial_interpolation.visualization import map_viz\n",
    "from spatial_interpolation.utils import tqdm_joblib\n",
    "\n",
    "from experiments.noaa.machine_learning.feature_extraction import FeatureExtractionExperiment\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "import dotenv\n",
    "\n",
    "# configs\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.filterwarnings('ignore', message='.*initial implementation of Parquet.*')\n",
    "dotenv.load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the data available:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "buoy_df, buoy_gdf = data.load_buoy_data(period=(\"2011-01-01\", \"2022-01-01\"))\n",
    "world_countries = data.load_world_borders()\n",
    "world_countries = world_countries[world_countries.overlaps(geometry.box(*buoy_gdf.total_bounds.tolist()))]\n",
    "# Remove the \"buoys\" that appear to be in land\n",
    "land_buoys = buoy_gdf.geometry.apply(lambda x: any(world_countries.intersects(x,align=False)))\n",
    "buoy_gdf = buoy_gdf[~land_buoys]\n",
    "buoy_df = buoy_df[buoy_df.index.get_level_values(\"buoy_id\").isin(buoy_gdf.index.get_level_values(\"buoy_id\").unique())]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Feature Extraction Experiment(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "set_conf = \"set1\"\n",
    "for y in range(2011,2022):\n",
    "    experiment_name = FeatureExtractionExperiment.__name__\n",
    "    p = subprocess.Popen([\"python\", \"-m\", \"experiments\", experiment_name , set_conf, f\"--year={y}\"])\n",
    "    print(f\"Started experiment {experiment_name} with config {set_conf} and year {y} on process {p.pid}\")\n",
    "    p.communicate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_make_features_at_year(conf, year, **kwargs):\n",
    "    experiment = FeatureExtractionExperiment(conf, year=year, **kwargs)\n",
    "    experiment.set_data((buoy_df, buoy_gdf))\n",
    "    _ = experiment.run()\n",
    "    return _"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.utils import io\n",
    "\n",
    "set_conf = \"set1\"\n",
    "# with io.capture_output() as captured:\n",
    "for y in range(2011,2022):\n",
    "    print(f\"Extracting features on {set_conf} for year {y}\")\n",
    "    run_make_features_at_year(set_conf, y, verbose=True)#, num_jobs=02)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = FeatureExtractionExperiment(\"set1\").get_config()\n",
    "train_df = pd.concat(\n",
    "    [pd.read_parquet(f\"{config.output.train_dir}/{year}.parquet\") for year in range(2011,2022)],\n",
    "    axis=0).sort_index()\n",
    "test_df = pd.concat(\n",
    "    [pd.read_parquet(f\"{config.output.eval_dir}/{year}.parquet\") for year in range(2011,2022)],\n",
    "    axis=0).sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "locations_within_area = buoy_gdf.loc[buoy_gdf.within(config.area)].index.get_level_values(\"buoy_id\").unique()\n",
    "print(\"Training set:\")\n",
    "print(\"Shape:\", train_df.shape)\n",
    "print(\"All within area?\",train_df.index.get_level_values(\"location_id\").isin(locations_within_area).all())\n",
    "print(\"Any eval buoys in train?\",train_df.index.get_level_values(\"location_id\").isin(config.locations_full).sum())\n",
    "print(\"Any eval index in train?\",train_df.index.isin(config.split_strategy.params.eval).sum())\n",
    "\n",
    "print(\"Eval set:\")\n",
    "print(\"Shape:\", test_df.shape)\n",
    "print(\"All within area?\",test_df.index.get_level_values(\"location_id\").isin(locations_within_area).all())\n",
    "print(\"Any eval buoys?\",test_df.index.get_level_values(\"location_id\").isin(config.locations_full).sum())\n",
    "print(\"Any eval index?\",test_df.index.isin(config.split_strategy.params.eval).sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Viz:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.options.plotting.backend = \"plotly\"\n",
    "fig = (\n",
    "    buoy_df\n",
    "    .loc[idx[\"42019\",\"1995-01-01\":],[\"wave_height\"]]\n",
    "    .loc[\"42019\"]\n",
    "    .resample(\"5D\").mean()\n",
    "    .plot(title=\\\n",
    "        f\"Historical of Wave Height for Buoy {buoy_gdf.loc[2011,'42019'].buoy_name}\",\n",
    "        # labels=dict(value=\"Wave Height (meters)\",variable=\"\"),\n",
    "    )\n",
    ")\n",
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_1_buoys = [\"41036\",\"42040\",\"42065\",\"41041\"]\n",
    "entire_area = geometry.box(*(-98.251934,12.282308,-45,35.55)) \n",
    "area_1 = geometry.box(*(-97.3,18.930645,-81.2,30.366655))\n",
    "area_2 = geometry.box(*(-82.836914,25.799891,-68.115234,35.55))\n",
    "box1_gdf = gpd.GeoDataFrame({\"geometry\":[area_1.union(area_2)]},crs=\"epsg:4326\")\n",
    "outer_box_gdf = gpd.GeoDataFrame({\"geometry\":[entire_area]},crs=\"epsg:4326\")\n",
    "\n",
    "available_buoys = buoy_df.index.get_level_values(\"buoy_id\").unique()\n",
    "available_buoys_gdf = buoy_gdf.loc[buoy_gdf.index.get_level_values(\"buoy_id\").isin(available_buoys)].reset_index()\n",
    "uniques = buoy_gdf.loc[idx[:,set_1_buoys],:].reset_index().drop_duplicates(subset=\"buoy_id\",keep=\"last\").set_index(\"buoy_id\")\n",
    "mp = map_viz.make_map_of_buoys(\n",
    "    location = available_buoys_gdf.unary_union.centroid.coords[0][::-1],\n",
    "    zoom_start = 4,\n",
    "    buoy_locations_df=available_buoys_gdf, \n",
    "    marker=partial(folium.CircleMarker, radius=1, weight=5,color=\"black\"),\n",
    ")\n",
    "map_viz.add_geodf_to_map(uniques.loc[set_1_buoys],map=mp, color=\"red\", radius=1, weight=5, layer_name=\"buoys from eval set 1\")\n",
    "area_1_gdf = gpd.GeoDataFrame({\"geometry\":[area_1]},crs=\"epsg:4326\")\n",
    "map_viz.add_geodf_to_map(utils.flip_coords(area_1_gdf),map=mp, layer_name=\"box2\", color=\"yellow\", alpha=0.5)\n",
    "map_viz.add_geodf_to_map(utils.flip_coords(box1_gdf),map=mp, layer_name=\"box1\",color=\"red\")\n",
    "map_viz.add_geodf_to_map(utils.flip_coords(outer_box_gdf),map=mp, layer_name=\"outer box\", color=\"blue\")\n",
    "folium.LayerControl().add_to(mp)\n",
    "mp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# locations with the most data points\n",
    "most_points = buoy_df[[\"wave_height\",\"wind_direction\"]].groupby(\n",
    "    \"buoy_id\"\n",
    ").count().sort_values(\n",
    "    by=[\"wave_height\",\"wind_direction\",\"buoy_id\"],\n",
    "    ascending=False)\n",
    "print(\"Locations with the most data points:\")\n",
    "display(most_points.head(10))\n",
    "# times with the most data points\n",
    "most_points = buoy_df[[\"wave_height\",\"wind_direction\"]].groupby(\n",
    "    \"time\"\n",
    ").count().sort_values(\n",
    "    by=[\"wave_height\",\"wind_direction\",\"time\"],\n",
    "    ascending=False)\n",
    "print(\"Times with the most data points:\")\n",
    "display(most_points.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5156605a370da4264d35700d255afe940b4002408cb66ca14decdceceba1912f"
  },
  "kernelspec": {
   "display_name": "Python 3.8.13 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
