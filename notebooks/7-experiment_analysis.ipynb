{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import mlflow, re\n",
    "\n",
    "# experiments\n",
    "from experiments.noaa.machine_learning import NOAAMLTraining, FeatureExtractionExperiment\n",
    "from experiments.noaa.deterministic import NOAADeterministicExperiment\n",
    "from experiments.noaa.kriging_experiment import NOAAKrigingExperiment\n",
    "from experiments.noaa import *\n",
    "client = mlflow.tracking.MlflowClient()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow_experiment = mlflow.get_experiment_by_name(NOAADeterministicExperiment.experiment_name)\n",
    "available_configs = NOAADeterministicExperiment.config.config.keys()\n",
    "df = mlflow.search_runs([mlflow_experiment.experiment_id]).sort_values([\"start_time\"], ascending=False)\n",
    "metric_cols =  df.columns[df.columns.str.contains(\"metrics\")].tolist()\n",
    "param_cols = [\"rbf\",\"params.epsilon\",\"params.eval_set\", \"tags.config\"]\n",
    "without_eps = [\"thin_plate_spline\", \"cubic\", \"idw\",\"linear\"]\n",
    "eps_results_df = (\n",
    "    df.dropna(how=\"all\",axis=1)\n",
    "    .loc[(df.start_time>\"2022-06-19 18:00:00\")]\n",
    "    .loc[(df[\"tags.config\"].str.contains(\"rbf\"))&(df.start_time>\"2022-06-19\")]\n",
    "    .assign(rbf=lambda x: x[\"tags.config\"].str.replace(\"rbf_(.*)_eps_(.*)\", r\"\\1\", regex=True))\n",
    "    .loc[:,param_cols+sorted(metric_cols)]\n",
    "    .replace(\n",
    "        {\"_set.\": \"\", \"linear\":\"linear_barycentric\", '\"':'', \"eps_.*\":\"\",\"_\": \" \"},\n",
    "        value=None,\n",
    "        regex=True\n",
    "    )\n",
    "    .groupby([\"params.eval_set\",\"rbf\"])\n",
    "    .apply(lambda x: x.sort_values(\"metrics.mae\",ascending=True))\n",
    "    .drop(columns=[\"params.eval_set\",\"rbf\", \"tags.config\"])\n",
    "    .dropna(subset=[\"metrics.rmse\"])\n",
    "    .rename(columns={col: col.replace(\"metrics.\",\"\").replace(\"params.\",\"\") for col in df.columns})\n",
    ")\n",
    "eps_results_df.loc[[\"set1\",\"set3\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "available_configs = NOAADeterministicExperiment.config.config.keys()\n",
    "mlflow_experiment = mlflow.get_experiment_by_name(NOAADeterministicExperiment.experiment_name)\n",
    "df = (\n",
    "    mlflow.search_runs([mlflow_experiment.experiment_id])\n",
    "    .dropna(how=\"all\",axis=1)\n",
    "    .set_index(\"run_id\")\n",
    "    .sort_values([\"start_time\"], ascending=False)\n",
    ")\n",
    "df = df.loc[(df.start_time>\"2022-06-19 18:00:00\")&(df[\"tags.config\"].isin(available_configs))]\n",
    "metric_cols =  df.columns[df.columns.str.contains(\"metrics\")].sort_values(ascending=False).tolist()\n",
    "param_cols = [\"params.epsilon\",\"params.eval_frac\",\"params.num_evaluated_points\",\"params.eval_set\", \"tags.config\"]\n",
    "without_eps = [\"thin_plate_spline\", \"cubic\", \"idw\",\"linear\"]\n",
    "results_by_set = (\n",
    "    df.dropna(how=\"all\",axis=1)\n",
    "    .drop_duplicates(subset=[\"tags.config\", \"params.eval_set\"], keep=\"first\")\n",
    "    # .assign(rbf=lambda x: x[\"tags.config\"].str.replace(\"rbf_(.*)_eps_(.*)\", r\"\\1\", regex=True))\n",
    "    .loc[:,param_cols+metric_cols]\n",
    "    .rename(columns={col: col.replace(\"metrics.\",\"\").replace(\"params.\",\"\") for col in df.columns})\n",
    "    .rename(columns={\"eval_set\":\"eval_area\"})#, \"tags.config\":\"algorithm\"})\n",
    "    .assign(\n",
    "        eval_area = lambda df: df.eval_area.str.replace(\"set\",\"Area \"), \n",
    "        inference_time_per_point = lambda df: (df.time_to_eval/df.num_evaluated_points.astype(int))*1000, # ms\n",
    "        algorithm = lambda df: df[\"tags.config\"].values\n",
    "    )\n",
    "    .replace(\n",
    "        {\"_set.\": \"\", \"linear\":\"linear_barycentric\", '\"':'', \"eps_.*\":\"\",\"_\": \" \"},\n",
    "        value=None,\n",
    "        regex=True\n",
    "    )\n",
    "    .assign(epsilon = lambda df: df.apply(lambda row: row.epsilon if not any(a in row.algorithm for a in without_eps) else \"-\", axis=1))\n",
    "    .groupby([\"eval_area\"])\n",
    "    .apply(lambda x: x.sort_values(\"rmse\",ascending=True))\n",
    "    .reset_index(level=-1,drop=True)\n",
    "    .drop_duplicates(subset=[\"eval_area\",\"algorithm\"], keep=\"last\")\n",
    "    .set_index(\"algorithm\", append=True)\n",
    "    .drop(columns=[\"eval_area\", \"time_to_eval\", \"tags.config\"])#, \"params.epsilon\"])\n",
    "    .dropna(subset=[\"rmse\"])\n",
    "    # .sort_index(axis=1, ascending=False)\n",
    ")\n",
    "# results_by_set = results_by_set[~results_by_set.index.get_level_values(\"algorithm\").str.contains(\"time\")]\n",
    "results_by_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(results_by_set.drop(columns=[\"eval_frac\", \"n_jobs\"]).round(3).to_latex(index=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_runs = (\n",
    "    df\n",
    "    .drop_duplicates(subset=[\"tags.config\", \"params.eval_set\"], keep=\"first\")\n",
    "    .dropna(subset=metric_cols)\n",
    ")\n",
    "df_partials = []\n",
    "for run_id in df_runs.index:\n",
    "    conf_name = df_runs.loc[run_id,\"tags.config\"].lower()\n",
    "    if \"time\" in conf_name or any(s in conf_name for s in [\"gaussian\", \"idw\"]):\n",
    "        continue\n",
    "    path = client.download_artifacts(run_id, \"partial_eval_metrics.html\")\n",
    "    df_partial = pd.read_html(path)[0]\n",
    "    # df.columns = pd.MultiIndex.from_columns(df.columns)\n",
    "    df_partial.columns = df_partial.columns.droplevel(-1)\n",
    "    df_partial.columns = [\"partial_set\"] + df_partial.columns.tolist()[1:]\n",
    "    df_partial = (\n",
    "        df_partial.assign(\n",
    "            algorithm = lambda df: conf_name,\n",
    "            eval_frac = lambda df: df_runs.loc[run_id,\"params.eval_frac\"].lower(),\n",
    "            eval_area = df_runs.loc[run_id,\"params.eval_set\"].replace(\"set\",\"Area \").replace('\"',\"\")\n",
    "        ).replace(\n",
    "            {\"_set.\": \"\", \"linear\":\"linear_barycentric\", '\"':'', \"eps_.*\":\"\",\"_\": \" \"},\n",
    "            value=None,\n",
    "            regex=True\n",
    "        )\n",
    "        # .set_index([\"eval_area\",\"algorithm\", \"partial_set\"])\n",
    "        .loc[:, [\"eval_area\",\"algorithm\", \"partial_set\"]+[\"rmse\", \"r2\", \"mae\"]]\n",
    "        .round(3)\n",
    "        .pivot_table(index=[\"eval_area\",\"algorithm\"], columns=\"partial_set\", values=[\"rmse\"])\n",
    "    )\n",
    "    df_partials.append(df_partial)\n",
    "partials_df = pd.concat(df_partials).sort_index()\n",
    "partials_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    partials_df\n",
    "    .to_latex(index=True)\n",
    "    .replace(\"NaN\", \"-\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------- \n",
    "### Kriging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "available_configs = NOAAKrigingExperiment.config.config.keys()\n",
    "mlflow_experiment = mlflow.get_experiment_by_name(NOAAKrigingExperiment.experiment_name)\n",
    "df = (\n",
    "    mlflow.search_runs([mlflow_experiment.experiment_id])\n",
    "    .dropna(how=\"all\",axis=1)\n",
    "    .set_index(\"run_id\")\n",
    "    .sort_values([\"start_time\"], ascending=False)\n",
    ")\n",
    "df = df.loc[(df.start_time>\"2022-06-19 18:00:00\")&(df[\"tags.config\"].isin(available_configs))]\n",
    "metric_cols =  df.columns[df.columns.str.contains(\"metrics\")].sort_values(ascending=False).tolist()\n",
    "param_cols = [\"params.model\",\"params.eval_frac\",\"params.num_evaluated_points\",\"params.eval_set\", \"tags.config\", \"params.n_jobs\"]\n",
    "results_by_set = (\n",
    "    df\n",
    "    .drop_duplicates(subset=[\"tags.config\", \"params.eval_set\"], keep=\"first\")\n",
    "    .loc[:,param_cols+metric_cols]\n",
    "    .dropna()\n",
    "    .assign(algorithm=lambda x: x[\"tags.config\"].str.replace(\"ordinary_kriging_(.*)\", r\"\\1\", regex=True))    \n",
    "    .rename(columns={col: col.replace(\"metrics.\",\"\").replace(\"params.\",\"\") for col in df.columns})\n",
    "    .rename(columns={\"eval_set\":\"eval_area\", \"tags.config\":\"algorithm\", \"model\":\"variogram\"})\n",
    "    .assign(\n",
    "        eval_area = lambda df: df.eval_area.str.replace(\"set\",\"Area \"), \n",
    "        inference_time_per_point = lambda df: (df.time_to_eval/df.num_evaluated_points.astype(int))*1000, # convert to ms\n",
    "    )\n",
    "    .replace(\n",
    "        {\"_set.\": \"\", \"ok\":\"ordinary kriging\", '\"':'',\"_\": \" \"},\n",
    "        value=None,\n",
    "        regex=True\n",
    "    )\n",
    "    .drop_duplicates(subset=[\"eval_area\",\"variogram\"], keep=\"first\")\n",
    "    .groupby([\"eval_area\"])\n",
    "    .apply(lambda x: x.sort_values(\"rmse\",ascending=True))\n",
    "    .reset_index(level=-1,drop=True)\n",
    "    .set_index(\"variogram\", append=True)\n",
    "    .drop(columns=[\"eval_area\",\"time_to_eval\",\"algorithm\", \"num_evaluated_points\"])#, \"params.epsilon\"])\n",
    "    .dropna(subset=[\"rmse\"])\n",
    "    # .sort_index(axis=1, ascending=False)\n",
    ")\n",
    "# results_by_set = results_by_set[~results_by_set.index.get_level_values(\"algorithm\").str.contains(\"time\")]\n",
    "results_by_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(results_by_set.drop(columns=[\"eval_frac\", \"n_jobs\"]).round(3).to_latex(index=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_runs = (\n",
    "    df\n",
    "    .drop_duplicates(subset=[\"tags.config\", \"params.eval_set\"], keep=\"first\")\n",
    "    .dropna(subset=metric_cols)\n",
    ")\n",
    "df_partials = []\n",
    "for run_id in df_runs.index:\n",
    "    conf_name = df_runs.loc[run_id,\"tags.config\"].lower()\n",
    "    if \"time\" in conf_name or any(s in conf_name for s in [\"gaussian\", \"idw\"]):\n",
    "        continue\n",
    "    path = client.download_artifacts(run_id, \"partial_eval_metrics.html\")\n",
    "    df_partial = pd.read_html(path)[0]\n",
    "    # df.columns = pd.MultiIndex.from_columns(df.columns)\n",
    "    df_partial.columns = df_partial.columns.droplevel(-1)\n",
    "    df_partial.columns = [\"partial_set\"] + df_partial.columns.tolist()[1:]\n",
    "    df_partial = (\n",
    "        df_partial.assign(\n",
    "            algorithm = \"OK \" + re.sub(\"ok_(.*)_.*\",r\"\\1\",df_runs.loc[run_id, \"tags.config\"]).capitalize(),\n",
    "            eval_area = df_runs.loc[run_id,\"params.eval_set\"].replace(\"set\",\"Area \").replace('\"',\"\")\n",
    "        ).replace(\n",
    "            {\"_set.\": \"\", \"linear\":\"linear_barycentric\", '\"':'', \"eps_.*\":\"\",\"_\": \" \"},\n",
    "            value=None,\n",
    "            regex=True\n",
    "        )\n",
    "        # .set_index([\"eval_area\",\"algorithm\", \"partial_set\"])\n",
    "        .loc[:, [\"eval_area\",\"algorithm\", \"partial_set\"]+[\"rmse\", \"r2\", \"mae\"]]\n",
    "        .round(3)\n",
    "        .pivot_table(index=[\"eval_area\",\"algorithm\"], columns=\"partial_set\", values=[\"rmse\"])\n",
    "    )\n",
    "    df_partials.append(df_partial)\n",
    "partials_df = pd.concat(df_partials).sort_index()\n",
    "partials_df.columns = partials_df.columns.droplevel(0)\n",
    "partials_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    re.sub(\n",
    "        \"&\\s+([a-f])\\s+&\",\n",
    "        lambda m: \" & \" + m.group(1).upper() + \" & \",\n",
    "        partials_df\n",
    "        .to_latex(index=True)\n",
    "        .replace(\"NaN\", \"-\")\n",
    "        .replace(\"eval_area\", \"Area\")\n",
    "        .replace(\"algorithm\", \"Algorithm\")\n",
    "    )\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    results_by_set\n",
    "    .reset_index()\n",
    "    .rename(columns={\n",
    "        \"algorithm\":\"rbf\", \n",
    "        \"num_evaluated_points\":\"evaluated points\", \n",
    "        \"inference_time_per_point\":\"inference time / point (ms)\",\n",
    "    })\n",
    "    .assign(rbf=lambda df: df.rbf.str.replace(\"rbf \",\"\"))\n",
    "    .replace({\"rbf\":\"\"},value=None)\n",
    "    .drop(columns=[\"eval_frac\"])\n",
    "    .round(3)\n",
    "    .round({\"inference time / point (ms)\":2})\n",
    "    .set_index([\"eval_area\",\"rbf\"])\n",
    "    .to_latex(index=True)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "available_configs = NOAAMLTraining.config.config.keys()\n",
    "mlflow_experiment = mlflow.get_experiment_by_name(NOAAMLTraining.experiment_name)\n",
    "df = (\n",
    "    mlflow.search_runs([mlflow_experiment.experiment_id])\n",
    "    .dropna(how=\"all\",axis=1)\n",
    "    .set_index(\"run_id\")\n",
    "    .sort_values([\"start_time\"], ascending=False)\n",
    ")\n",
    "df = df.loc[(df.start_time>\"2022-06-22 22:00:00\")&(df[\"tags.config\"].isin(available_configs))]\n",
    "metric_cols =  [\"metrics.rmse\", \"metrics.r2\", \"metrics.mae\", \"metrics.inference_time\", \"metrics.fit_time\" ]\n",
    "param_cols = [\"params.model\", \"tags.config\", \"params.eval_set\"]\n",
    "results_by_set = (\n",
    "    df\n",
    "    .assign(**{\n",
    "        \"metrics.inference_time\":lambda df: np.where(df[\"metrics.inference_time\"].isnull(), df[\"params.inference_time\"], df[\"metrics.inference_time\"]).astype(float),\n",
    "        \"metrics.fit_time\":lambda df: np.where(df[\"metrics.fit_time\"].isnull(), df[\"params.fit_time\"], df[\"metrics.fit_time\"]).astype(float),\n",
    "        \"metrics.mae\": lambda df: np.where(df[\"metrics.mae\"].isnull(), df[\"metrics.eval_mae\"], df[\"metrics.mae\"]).astype(float),\n",
    "    })\n",
    "    # .drop_duplicates(subset=[\"tags.config\", \"params.eval_set\"], keep=\"first\")\n",
    "    .loc[:,param_cols+metric_cols]\n",
    "    # .dropna()\n",
    "    .rename(columns={col: col.replace(\"metrics.\",\"\").replace(\"params.\",\"\") for col in df.columns})\n",
    "    # .rename(columns={\"eval_set\":\"eval_area\"})\n",
    "    .assign(\n",
    "        eval_area = lambda df: df[\"tags.config\"].str.split(\"_\").str[-1].str.replace(\"set\",\"Area \"), \n",
    "        inference_time = lambda df: (df.inference_time)*1000, # convert to ms\n",
    "    )\n",
    "    .replace(\n",
    "        {\"_set.\": \"\", \"ok\":\"ordinary kriging\", '\"':'',\"_\": \" \"},\n",
    "        value=None,\n",
    "        regex=True\n",
    "    )\n",
    "    .assign(model=lambda x: x[\"model\"].str.split(\".\").str[-1].str[:-2].str.capitalize())\n",
    "    # .drop_duplicates(subset=[\"eval_area\",\"model\"], keep=\"first\")\n",
    "    .groupby([\"eval_area\"])\n",
    "    .apply(lambda x: x.sort_values(\"rmse\",ascending=True))\n",
    "    .reset_index(level=-1,drop=True)\n",
    "    .set_index(\"model\", append=True)\n",
    "    .drop(columns=[\"eval_area\", \"eval_set\", \"tags.config\"])#, \"params.epsilon\"])\n",
    "    .sort_index(axis=1, ascending=False)\n",
    "    .round(4)\n",
    ")\n",
    "# results_by_set = results_by_set[~results_by_set.index.get_level_values(\"algorithm\").str.contains(\"time\")]\n",
    "results_by_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    results_by_set\n",
    "    .to_latex(index=True)\n",
    "    .replace(\"regressor\", \"\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_runs = (\n",
    "    df\n",
    "    .drop_duplicates(subset=[\"tags.config\", \"params.eval_set\"], keep=\"first\")\n",
    "    .dropna(subset=metric_cols)\n",
    ")\n",
    "df_partials = []\n",
    "for run_id in df_runs.index:\n",
    "    conf_name = df_runs.loc[run_id,\"tags.config\"].lower()\n",
    "    if \"time\" in conf_name or any(s in conf_name for s in [\"gaussian\", \"idw\"]):\n",
    "        continue\n",
    "    path = client.download_artifacts(run_id, \"partial_eval_metrics.html\")\n",
    "    df_partial = pd.read_html(path)[0]\n",
    "    # df.columns = pd.MultiIndex.from_columns(df.columns)\n",
    "    df_partial.columns = df_partial.columns.droplevel(-1)\n",
    "    df_partial.columns = [\"partial_set\"] + df_partial.columns.tolist()[1:]\n",
    "    df_partial = (\n",
    "        df_partial.assign(\n",
    "            algorithm = re.sub(\"ok_(.*)_.*\",r\"\\1\",df_runs.loc[run_id, \"tags.config\"]).replace(\"config\",\"\".strip()).split(\".\")[0],\n",
    "            eval_area = df_runs.loc[run_id,\"params.eval_set\"].replace(\"set\",\"Area \").replace('\"',\"\")\n",
    "        ).replace(\n",
    "            {\"_set.\": \"\", \"linear\":\"linear_barycentric\", '\"':'', \"eps_.*\":\"\",\"_\": \" \"},\n",
    "            value=None,\n",
    "            regex=True\n",
    "        )\n",
    "        # .set_index([\"eval_area\",\"algorithm\", \"partial_set\"])\n",
    "        .loc[:, [\"eval_area\",\"algorithm\", \"partial_set\"]+[\"rmse\", \"r2\", \"mae\"]]\n",
    "        .round(3)\n",
    "        .pivot_table(index=[\"eval_area\",\"algorithm\"], columns=\"partial_set\", values=[\"rmse\"])\n",
    "    )\n",
    "    df_partials.append(df_partial)\n",
    "partials_df = pd.concat(df_partials).sort_index()\n",
    "partials_df.columns = partials_df.columns.droplevel(0)\n",
    "partials_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    re.sub(\n",
    "        \"&\\s+([a-f])\\s+&\",\n",
    "        lambda m: \" & \" + m.group(1).upper() + \" & \",\n",
    "        partials_df\n",
    "        .to_latex(index=True)\n",
    "        .replace(\"NaN\", \"-\")\n",
    "        .replace(\"eval\\_area\", \"Area\")\n",
    "        .replace(\"partial\\_set\", \"Partial Set\")\n",
    "        .replace(\"algorithm\", \"Model\")\n",
    "    )\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "available_configs = NOAARegressionKrigingExperiment.config.config.keys()\n",
    "mlflow_experiment = mlflow.get_experiment_by_name(NOAAKrigingExperiment.experiment_name)\n",
    "df = (\n",
    "    mlflow.search_runs([mlflow_experiment.experiment_id])\n",
    "    .dropna(how=\"all\",axis=1)\n",
    "    .set_index(\"run_id\")\n",
    "    .sort_values([\"start_time\"], ascending=False)\n",
    ")\n",
    "df = df[df[\"tags.config\"].str.startswith(\"rk\")]\n",
    "\n",
    "df = df.loc[(df.start_time>\"2022-06-22 22:00:00\")&(df[\"tags.config\"].isin(available_configs))]\n",
    "metric_cols =  df.columns[df.columns.str.contains(\"metrics\")].sort_values(ascending=False).tolist()\n",
    "param_cols = [\"params.model\",\"params.eval_frac\",\"params.num_evaluated_points\",\"params.eval_set\", \"tags.config\", \"params.n_jobs\"]\n",
    "\n",
    "results_by_set = (\n",
    "    df\n",
    "    .drop_duplicates(subset=[\"tags.config\", \"params.eval_set\"], keep=\"first\")\n",
    "    .loc[:,param_cols+metric_cols]\n",
    "    .dropna()\n",
    "    .assign(algorithm=lambda x: x[\"tags.config\"].str.replace(\"ordinary_kriging_(.*)\", r\"\\1\", regex=True))    \n",
    "    .rename(columns={col: col.replace(\"metrics.\",\"\").replace(\"params.\",\"\") for col in df.columns})\n",
    "    .rename(columns={\"eval_set\":\"eval_area\", \"tags.config\":\"algorithm\", \"model\":\"variogram\"})\n",
    "    .assign(\n",
    "        eval_area = lambda df: df.eval_area.str.replace(\"set\",\"Area \"), \n",
    "        inference_time_per_point = lambda df: (df.time_to_eval/df.num_evaluated_points.astype(int))*1000, # convert to ms\n",
    "    )\n",
    "    .replace(\n",
    "        {\"_set.\": \"\", \"ok\":\"ordinary kriging\", '\"':'',\"_\": \" \"},\n",
    "        value=None,\n",
    "        regex=True\n",
    "    )\n",
    "    .drop_duplicates(subset=[\"eval_area\",\"variogram\"], keep=\"first\")\n",
    "    .groupby([\"eval_area\"])\n",
    "    .apply(lambda x: x.sort_values(\"rmse\",ascending=True))\n",
    "    .reset_index(level=-1,drop=True)\n",
    "    .set_index(\"variogram\", append=True)\n",
    "    .drop(columns=[\"eval_area\",\"time_to_eval\",\"algorithm\", \"num_evaluated_points\"])#, \"params.epsilon\"])\n",
    "    .dropna(subset=[\"rmse\"])\n",
    "    # .sort_index(axis=1, ascending=False)\n",
    ")\n",
    "# results_by_set = results_by_set[~results_by_set.index.get_level_values(\"algorithm\").str.contains(\"time\")]\n",
    "results_by_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(results_by_set.drop(columns=[\"eval_frac\", \"n_jobs\"]).round(3).to_latex(index=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_runs = (\n",
    "    df\n",
    "    .drop_duplicates(subset=[\"tags.config\", \"params.eval_set\"], keep=\"first\")\n",
    "    .dropna(subset=metric_cols)\n",
    ")\n",
    "df_partials = []\n",
    "for run_id in df_runs.index:\n",
    "    conf_name = df_runs.loc[run_id,\"tags.config\"].lower()\n",
    "    if \"time\" in conf_name: #or any(s in conf_name for s in [\"gaussian\", \"idw\"]):\n",
    "        continue\n",
    "    path = client.download_artifacts(run_id, \"partial_eval_metrics.html\")\n",
    "    df_partial = pd.read_html(path)[0]\n",
    "    # df.columns = pd.MultiIndex.from_columns(df.columns)\n",
    "    df_partial.columns = df_partial.columns.droplevel(-1)\n",
    "    df_partial.columns = [\"partial_set\"] + df_partial.columns.tolist()[1:]\n",
    "    df_partial = (\n",
    "        df_partial.assign(\n",
    "            algorithm = re.sub(\"rk_(.*)_.*\",r\"\\1\",df_runs.loc[run_id, \"tags.config\"]).capitalize(),\n",
    "            eval_area = df_runs.loc[run_id,\"params.eval_set\"].replace(\"set\",\"Area \").replace('\"',\"\")\n",
    "        ).replace(\n",
    "            {\"_set.\": \"\", \"linear\":\"linear_barycentric\", '\"':'', \"eps_.*\":\"\",\"_\": \" \"},\n",
    "            value=None,\n",
    "            regex=True\n",
    "        )\n",
    "        # .set_index([\"eval_area\",\"algorithm\", \"partial_set\"])\n",
    "        .loc[:, [\"eval_area\",\"algorithm\", \"partial_set\"]+[\"rmse\", \"r2\", \"mae\"]]\n",
    "        .round(3)\n",
    "        .pivot_table(index=[\"eval_area\",\"algorithm\"], columns=\"partial_set\", values=[\"rmse\"])\n",
    "    )\n",
    "    df_partials.append(df_partial)\n",
    "partials_df = pd.concat(df_partials).sort_index()\n",
    "partials_df.columns = partials_df.columns.droplevel(0)\n",
    "partials_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(partials_df.to_latex(index=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "available_configs = NOAARegressionKrigingExperiment.config.config.keys()\n",
    "experiment_name = NOAARegressionKrigingExperiment.__name__\n",
    "c = 0\n",
    "for config_name in available_configs: \n",
    "    c += 1\n",
    "    if \"linear\" in config_name or \"matern\" in config_name:\n",
    "        continue\n",
    "    print(config_name)\n",
    "    eval_frac = \"0.2\" #if \"set1\" in config_name else \"0.1\"\n",
    "    p = subprocess.Popen([\"python\", \"-m\", \"experiments\", experiment_name , config_name, \"--eval_frac=0.5\"])\n",
    "    print(f\"Started experiment {config_name} on process {p.pid}\")\n",
    "    p.communicate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "available_configs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5156605a370da4264d35700d255afe940b4002408cb66ca14decdceceba1912f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
